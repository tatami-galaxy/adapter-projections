{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF8MtemvzXI9"
      },
      "outputs": [],
      "source": [
        "import random, os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(567)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMd-xcgaJeGE"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install git+https://github.com/tatami-galaxy/adapter-projections.git\n",
        "!pip install datasets\n",
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU6DM5xqATgO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/MyDrive/subspace.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmWyYUjdhhFv"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siFXeEuyhZ0t"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoConfig, XLMRobertaAdapterModel\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import nn\n",
        "import copy\n",
        "from transformers import AdapterConfig\n",
        "from datasets import load_dataset\n",
        "from transformers import TrainingArguments\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import TrainingArguments, AdapterTrainer, EvalPrediction\n",
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "from transformers.adapters.composition import Stack\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhfxhT_9rthv"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kARdJlT6hj0X"
      },
      "outputs": [],
      "source": [
        "#The labels for the NER task and the dictionaries to map the to ids or \n",
        "#the other way around\n",
        "labels = [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\"]\n",
        "id_2_label = {id_: label for id_, label in enumerate(labels)}\n",
        "label_2_id = {label: id_ for id_, label in enumerate(labels)}\n",
        "\n",
        "model_name = \"xlm-roberta-base\"\n",
        "config = AutoConfig.from_pretrained(model_name, num_labels=len(labels), label2id=label_2_id, id2label=id_2_label)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = XLMRobertaAdapterModel.from_pretrained(model_name, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiJdN42kA2s7"
      },
      "outputs": [],
      "source": [
        "model.load_adapter_projections(['de', 'hi', 'is', 'es', 'id', 'ja', 'ta', 'th'], 0.9, '/content/subspace_cache')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSY0PtEYVZ4a"
      },
      "outputs": [],
      "source": [
        "src_lang = \"en\" \n",
        "tgt_lang = \"ja\" \n",
        "\n",
        "# Load the language adapters\n",
        "lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
        "model.load_adapter(src_lang+\"/wiki@ukp\", config=lang_adapter_config) # leave_out=[11])\n",
        "model.load_adapter(tgt_lang+\"/wiki@ukp\", config=lang_adapter_config) # leave_out=[11])\n",
        "\n",
        "# Add a new task adapter\n",
        "model.add_adapter(\"wikiann\")\n",
        "\n",
        "model.add_tagging_head(\"wikiann\", num_labels=len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1uXfq1OSI6D"
      },
      "outputs": [],
      "source": [
        "model.train_adapter([\"wikiann\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqBh8-QCrv53"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afFIwNWTr9jW"
      },
      "outputs": [],
      "source": [
        "dataset_src = load_dataset('wikiann', src_lang)\n",
        "dataset_tgt = load_dataset('wikiann', tgt_lang)\n",
        "\n",
        "# This method is adapted from the huggingface transformers run_ner.py example script\n",
        "# Tokenize all texts and align the labels with them.\n",
        "def tokenize_and_align_labels(examples):\n",
        "    text_column_name = \"tokens\"\n",
        "    label_column_name = \"ner_tags\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[text_column_name],\n",
        "        padding=False,\n",
        "        truncation=True,\n",
        "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[label_column_name]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.  \n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "  \n",
        "dataset_src = dataset_src.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=dataset_src[\"train\"].column_names,\n",
        ")\n",
        "dataset_tgt = dataset_tgt.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=dataset_tgt[\"train\"].column_names,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LryV6LVvTkF2"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9Br3IA1agCo"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    dataset_src[\"train\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=16,\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    dataset_tgt[\"validation\"], collate_fn=data_collator, batch_size=16\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset_tgt[\"test\"], collate_fn=data_collator, batch_size=16\n",
        ")\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_train_epochs = 15\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n2tQ4Z5_k__"
      },
      "outputs": [],
      "source": [
        "def postprocess(predictions, labels):\n",
        "    predictions = predictions.detach().cpu().clone().numpy()\n",
        "    labels = labels.detach().cpu().clone().numpy()\n",
        "    label_list = id_2_label\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    return true_labels, true_predictions\n",
        "\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7GeqwHiagI8"
      },
      "outputs": [],
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "\n",
        "    # Unfreeze and activate stack setup\n",
        "    model.active_adapters = Stack(src_lang, \"wikiann\")\n",
        "    model.activate_adapter_projection_stack('wikiann', 6, 'ja', 0.5)\n",
        "\n",
        "    val_loss = 0\n",
        "    # Training\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        inputs = batch['input_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids=inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    model.disable_adapter_projection_stack()\n",
        "    model.active_adapters = Stack(tgt_lang, \"wikiann\")\n",
        "    for batch in eval_dataloader:\n",
        "        with torch.no_grad():\n",
        "          inputs = batch['input_ids'].to(device)\n",
        "          labels = batch['labels'].to(device)\n",
        "          outputs = model(input_ids=inputs, labels=labels)\n",
        "          val_loss += outputs.loss.item()\n",
        "\n",
        "        predictions = outputs.logits.argmax(dim=2)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        # Necessary to pad predictions and labels for being gathered\n",
        "        #predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
        "        #labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
        "\n",
        "        #predictions_gathered = accelerator.gather(predictions)\n",
        "        #labels_gathered = accelerator.gather(labels)\n",
        "\n",
        "        true_predictions, true_labels = postprocess(predictions, labels)\n",
        "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "    results = metric.compute()\n",
        "    print(\n",
        "        f\"epoch {epoch}:\",\n",
        "        {\n",
        "            key: results[f\"overall_{key}\"]\n",
        "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
        "        },\n",
        "    )\n",
        "    print(val_loss/len(eval_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "for batch in test_dataloader:\n",
        "    with torch.no_grad():\n",
        "        inputs = batch['input_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids=inputs, labels=labels)\n",
        "        test_loss += outputs.loss.item()\n",
        "\n",
        "    predictions = outputs.logits.argmax(dim=2)\n",
        "    labels = batch[\"labels\"]\n",
        "\n",
        "        # Necessary to pad predictions and labels for being gathered\n",
        "        #predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
        "        #labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
        "\n",
        "        #predictions_gathered = accelerator.gather(predictions)\n",
        "        #labels_gathered = accelerator.gather(labels)\n",
        "\n",
        "    true_predictions, true_labels = postprocess(predictions, labels)\n",
        "    metric.add_batch(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "results = metric.compute()\n",
        "print(f\"epoch {epoch}:\", {key: results[f\"overall_{key}\"] for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]},)\n",
        "print(test_loss/len(test_dataloader))"
      ],
      "metadata": {
        "id": "MZlAvmxVYySr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L463VUlTHkQm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MADX_NER_TGT_Val_XLMR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}